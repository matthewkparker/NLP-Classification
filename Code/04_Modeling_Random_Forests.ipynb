{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattm\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\mattm\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mtrand.RandomState at 0x2dd6cbed678>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../Data/X_train.csv\",index_col=0)\n",
    "y_train = pd.read_csv(\"../Data/y_train.csv\",index_col=0)\n",
    "with open('../Assets/custom_stop_words.pkl','rb') as f:\n",
    "    custom_stop_words = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell instantiates a Pipeline, which will process the data, and  determines which model I will use in this notebook, which is the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidif\", TfidfVectorizer()),\n",
    "    (\"RFC\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary lists the hyper parameters that I want my Gridsearch to test, which will then pick a single model. Gridsearch will then use the model that had the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"tfidif__stop_words\":[custom_stop_words],\n",
    "    \"tfidif__min_df\":[5],\n",
    "    'RFC__max_features':['auto','log2',5,10],\n",
    "    \"RFC__n_estimators\":[10,50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max_features is the amount of words that we want to split each tree in our random forest on\n",
    "N_estimators is the number of individual decision trees that our model will use to ultimately classify our data. Auto takes the square root of the total number of features, and log2 determines the number of features using the equation log2(n_features) = max_features. The min_df parameter is saying that in order for a word to be considered in the model, it must show up in at least 5 documents. This is done in order to reduce the overall number of feature. Most is not all of the words being eliminated should have no importance in determining each class if it shows up in less than 5 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_RanFor = GridSearchCV(pipe,param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidif', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'tfidif__stop_words': [['bill', 'however', 'move', 'whoever', 'becoming', 'detail', 'here', 'she', 'its', 'forty', 'sometimes', 'yours', 'describe', 'seem', 'thereby', 'may', 'and', 'these', 'along', 'still', 'yourselves', 'three', 'whether', 'none', 'themselves', 'first', 'two', 'before...dif__min_df': [5], 'RFC__max_features': ['auto', 'log2', 5, 10], 'RFC__n_estimators': [10, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_RanFor.fit(X_train['Total_text'],y_train['subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log2\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(gs_RanFor.best_params_['RFC__max_features'])\n",
    "print(gs_RanFor.best_params_['RFC__n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our random forest, our model performed the best when max features is set to log2, and the number of estimators is equal to 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Saving our Random Forrest Classifier to be evaluated later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Assets/Ranfor.pkl','wb+') as f:\n",
    "    pickle.dump(gs_RanFor,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
